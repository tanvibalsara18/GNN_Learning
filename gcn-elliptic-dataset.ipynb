{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-20T23:32:47.883646Z",
     "iopub.status.busy": "2022-07-20T23:32:47.882532Z",
     "iopub.status.idle": "2022-07-20T23:32:47.884291Z",
     "shell.execute_reply": "2022-07-20T23:32:47.884717Z"
    },
    "papermill": {
     "duration": 0.026293,
     "end_time": "2022-07-20T23:32:47.884851",
     "exception": false,
     "start_time": "2022-07-20T23:32:47.858558",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_data(data_dir, start_ts, end_ts):\n",
    "\tclasses_csv = 'elliptic_txs_classes.csv'\n",
    "\tedgelist_csv = 'elliptic_txs_edgelist.csv'\n",
    "\tfeatures_csv = 'elliptic_txs_features.csv'\n",
    "\n",
    "\tclasses = pd.read_csv(os.path.join(data_dir, classes_csv), index_col = 'txId') # labels for the transactions i.e. 'unknown', '1', '2'\n",
    "\tedgelist = pd.read_csv(os.path.join(data_dir, edgelist_csv), index_col = 'txId1') # directed edges between transactions\n",
    "\tfeatures = pd.read_csv(os.path.join(data_dir, features_csv), header = None, index_col = 0) # features of the transactions\n",
    "\t\n",
    "\tnum_features = features.shape[1]\n",
    "\tnum_tx = features.shape[0]\t\n",
    "\ttotal_tx = list(classes.index)\n",
    "\n",
    "\t# select only the transactions which are labelled\n",
    "\tlabelled_classes = classes[classes['class'] != 'unknown']\n",
    "\tlabelled_tx = list(labelled_classes.index)\n",
    "\n",
    "\t# to calculate a list of adjacency matrices for the different timesteps\n",
    "\n",
    "\tadj_mats = []\n",
    "\tfeatures_labelled_ts = []\n",
    "\tclasses_ts = []\n",
    "\tnum_ts = 49 # number of timestamps from the paper\n",
    "\n",
    "\tfor ts in range(start_ts, end_ts):\n",
    "\t    features_ts = features[features[1] == ts+1]\n",
    "\t    tx_ts = list(features_ts.index)\n",
    "\t    \n",
    "\t    labelled_tx_ts = [tx for tx in tx_ts if tx in set(labelled_tx)]\n",
    "\t    \n",
    "\t    # adjacency matrix for all the transactions\n",
    "\t    # we will only fill in the transactions of this timestep which have labels and can be used for training\n",
    "\t    adj_mat = pd.DataFrame(np.zeros((num_tx, num_tx)), index = total_tx, columns = total_tx)\n",
    "\t    \n",
    "\t    edgelist_labelled_ts = edgelist.loc[edgelist.index.intersection(labelled_tx_ts).unique()]\n",
    "\t    for i in range(edgelist_labelled_ts.shape[0]):\n",
    "\t        adj_mat.loc[edgelist_labelled_ts.index[i], edgelist_labelled_ts.iloc[i]['txId2']] = 1\n",
    "\t    \n",
    "\t    adj_mat_ts = adj_mat.loc[labelled_tx_ts, labelled_tx_ts]\n",
    "\t    features_l_ts = features.loc[labelled_tx_ts]\n",
    "\t    \n",
    "\t    adj_mats.append(adj_mat_ts)\n",
    "\t    features_labelled_ts.append(features_l_ts)\n",
    "\t    classes_ts.append(classes.loc[labelled_tx_ts])\n",
    "\n",
    "\treturn adj_mats, features_labelled_ts, classes_ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-20T23:32:47.914153Z",
     "iopub.status.busy": "2022-07-20T23:32:47.913600Z",
     "iopub.status.idle": "2022-07-20T23:39:14.335281Z",
     "shell.execute_reply": "2022-07-20T23:39:14.335807Z"
    },
    "papermill": {
     "duration": 386.444411,
     "end_time": "2022-07-20T23:39:14.335980",
     "exception": false,
     "start_time": "2022-07-20T23:32:47.891569",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import sys\n",
    "import pandas as pd\n",
    "import os\n",
    "dir = \"../input/elliptic-data-set/elliptic_bitcoin_dataset\"\n",
    "dataSet = load_data(dir, 0, 34)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-20T23:39:14.364322Z",
     "iopub.status.busy": "2022-07-20T23:39:14.363279Z",
     "iopub.status.idle": "2022-07-20T23:39:15.732560Z",
     "shell.execute_reply": "2022-07-20T23:39:15.731677Z"
    },
    "papermill": {
     "duration": 1.390371,
     "end_time": "2022-07-20T23:39:15.732699",
     "exception": false,
     "start_time": "2022-07-20T23:39:14.342328",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "import sys\n",
    "\n",
    "class GraphConv(nn.Module):\n",
    "    def __init__(self, in_features, out_features, activation  = 'relu', skip = False, skip_in_features = None):\n",
    "        super(GraphConv, self).__init__()\n",
    "        self.W = torch.nn.Parameter(torch.DoubleTensor(in_features, out_features))\n",
    "        nn.init.xavier_uniform_(self.W)\n",
    "        \n",
    "        self.set_act = False\n",
    "        if activation == 'relu':\n",
    "            self.activation = nn.ReLU()\n",
    "            self.set_act = True\n",
    "        elif activation == 'softmax':\n",
    "            self.activation = nn.Softmax(dim = 1)\n",
    "            self.set_act = True\n",
    "        else:\n",
    "            self.set_act = False\n",
    "            raise ValueError(\"activations supported are 'relu' and 'softmax'\")\n",
    "            \n",
    "        self.skip = skip\n",
    "        if self.skip:\n",
    "            if skip_in_features == None:\n",
    "                raise ValueError(\"pass input feature size of the skip connection\")\n",
    "            self.W_skip = torch.nn.Parameter(torch.DoubleTensor(skip_in_features, out_features)) \n",
    "            nn.init.xavier_uniform_(self.W)\n",
    "        \n",
    "    def forward(self, A, H_in, H_skip_in = None):\n",
    "        # A must be an n x n matrix as it is an adjacency matrix\n",
    "        # H is the input of the node embeddings, shape will n x in_features\n",
    "        self.A = A\n",
    "        self.H_in = H_in\n",
    "        A_ = torch.add(self.A, torch.eye(self.A.shape[0]).double())\n",
    "        D_ = torch.diag(A_.sum(1))\n",
    "        # since D_ is a diagonal matrix, \n",
    "        # its root will be the roots of the diagonal elements on the principle diagonal\n",
    "        # since A is an adjacency matrix, we are only dealing with positive values \n",
    "        # all roots will be real\n",
    "        D_root_inv = torch.inverse(torch.sqrt(D_))\n",
    "        A_norm = torch.mm(torch.mm(D_root_inv, A_), D_root_inv)\n",
    "        # shape of A_norm will be n x n\n",
    "        \n",
    "        H_out = torch.mm(torch.mm(A_norm, H_in), self.W)\n",
    "        # shape of H_out will be n x out_features\n",
    "        \n",
    "        if self.skip:\n",
    "            H_skip_out = torch.mm(H_skip_in, self.W_skip)\n",
    "            H_out = torch.add(H_out, H_skip_out)\n",
    "        \n",
    "        if self.set_act:\n",
    "            H_out = self.activation(H_out)\n",
    "            \n",
    "        return H_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-20T23:39:15.755067Z",
     "iopub.status.busy": "2022-07-20T23:39:15.753275Z",
     "iopub.status.idle": "2022-07-20T23:39:15.755874Z",
     "shell.execute_reply": "2022-07-20T23:39:15.756296Z"
    },
    "papermill": {
     "duration": 0.017889,
     "end_time": "2022-07-20T23:39:15.756397",
     "exception": false,
     "start_time": "2022-07-20T23:39:15.738508",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class GCN_2layer(nn.Module):\n",
    "    def __init__(self, in_features, hidden_features, out_features, skip = False):\n",
    "        super(GCN_2layer, self).__init__()\n",
    "        self.skip = skip\n",
    "        \n",
    "        self.gcl1 = GraphConv(in_features, hidden_features)\n",
    "        \n",
    "        if self.skip:\n",
    "            self.gcl_skip = GraphConv(hidden_features, out_features, activation = 'softmax', skip = self.skip,\n",
    "                                  skip_in_features = in_features)\n",
    "        else:\n",
    "            self.gcl2 = GraphConv(hidden_features, out_features, activation = 'softmax')\n",
    "        \n",
    "    def forward(self, A, X):\n",
    "        out = self.gcl1(A, X)\n",
    "        if self.skip:\n",
    "            out = self.gcl_skip(A, out, X)\n",
    "        else:\n",
    "            out = self.gcl2(A, out)\n",
    "            \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-20T23:39:15.772121Z",
     "iopub.status.busy": "2022-07-20T23:39:15.771173Z",
     "iopub.status.idle": "2022-07-20T23:39:16.459006Z",
     "shell.execute_reply": "2022-07-20T23:39:16.457435Z"
    },
    "papermill": {
     "duration": 0.696861,
     "end_time": "2022-07-20T23:39:16.459111",
     "exception": false,
     "start_time": "2022-07-20T23:39:15.762250",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!mkdir modelDir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-20T23:39:16.495952Z",
     "iopub.status.busy": "2022-07-20T23:39:16.494811Z",
     "iopub.status.idle": "2022-07-20T23:42:19.552291Z",
     "shell.execute_reply": "2022-07-20T23:42:19.551770Z"
    },
    "papermill": {
     "duration": 183.087069,
     "end_time": "2022-07-20T23:42:19.552407",
     "exception": false,
     "start_time": "2022-07-20T23:39:16.465338",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 14/15 Timestamp 33/34 training loss: 0.373842 training accuracy: 0.970874 Time: 0.04603242874145508"
     ]
    }
   ],
   "source": [
    "num_features = 166\n",
    "num_classes = 2\n",
    "num_ts = 49\n",
    "epochs = 15\n",
    "lr = 0.001\n",
    "max_train_ts = 34\n",
    "train_ts = np.arange(max_train_ts)\n",
    "\n",
    "adj_mats, features_labelled_ts, classes_ts = dataSet\n",
    "\n",
    "# 0 - illicit, 1 - licit\n",
    "labels_ts = []\n",
    "for c in classes_ts:\n",
    "    labels_ts.append(np.array(c['class'] == '2', dtype = np.long))\n",
    "\n",
    "gcn = GCN_2layer(num_features, 100, num_classes)\n",
    "train_loss = nn.CrossEntropyLoss(weight = torch.DoubleTensor([0.7, 0.3]))\n",
    "optimizer = torch.optim.Adam(gcn.parameters(), lr = lr)\n",
    "\n",
    "# Training\n",
    "\n",
    "for ts in train_ts:\n",
    "    A = torch.tensor(adj_mats[ts].values)\n",
    "    X = torch.tensor(features_labelled_ts[ts].values)\n",
    "    L = torch.tensor(labels_ts[ts], dtype = torch.long)\n",
    "    for ep in range(epochs):\n",
    "        t_start = time.time()\n",
    "        \n",
    "        gcn.train()\n",
    "        optimizer.zero_grad()\n",
    "        out = gcn(A, X)\n",
    "\n",
    "        loss = train_loss(out, L)\n",
    "        train_pred = out.max(1)[1].type_as(L)\n",
    "        acc = (train_pred.eq(L).double().sum())/L.shape[0]\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        sys.stdout.write(\"\\r Epoch %d/%d Timestamp %d/%d training loss: %f training accuracy: %f Time: %s\"\n",
    "                         %(ep, epochs, ts, max_train_ts, loss, acc, time.time() - t_start)\n",
    "                        )\n",
    "\n",
    "torch.save(gcn.state_dict(), str(os.path.join(\"./modelDir\", \"gcn_weights.pth\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-20T23:42:19.742387Z",
     "iopub.status.busy": "2022-07-20T23:42:19.741764Z",
     "iopub.status.idle": "2022-07-20T23:45:26.312311Z",
     "shell.execute_reply": "2022-07-20T23:45:26.313052Z"
    },
    "papermill": {
     "duration": 186.673081,
     "end_time": "2022-07-20T23:45:26.313210",
     "exception": false,
     "start_time": "2022-07-20T23:42:19.640129",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCN - averaged accuracy: 0.9511561856887062, precision: 0.9710830104322657, recall: 0.9767505850872585, f1: 0.9735942196120048\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "test_ts = np.arange(14)\n",
    "adj_mats, features_labelled_ts, classes_ts = load_data(dir, 35, 49)\n",
    "\n",
    "# 0 - illicit, 1 - licit\n",
    "labels_ts = []\n",
    "for c in classes_ts:\n",
    "    labels_ts.append(np.array(c['class'] == '2', dtype = np.long))\n",
    "\n",
    "gcn = GCN_2layer(num_features, 100, num_classes)\n",
    "gcn.load_state_dict(torch.load(os.path.join(\"./modelDir\", \"gcn_weights.pth\")))\n",
    "\n",
    "# Testing\n",
    "test_accs = []\n",
    "test_precisions = []\n",
    "test_recalls = []\n",
    "test_f1s = []\n",
    "\n",
    "for ts in test_ts:\n",
    "    A = torch.tensor(adj_mats[ts].values)\n",
    "    X = torch.tensor(features_labelled_ts[ts].values)\n",
    "    L = torch.tensor(labels_ts[ts], dtype = torch.long)\n",
    "    \n",
    "    gcn.eval()\n",
    "    test_out = gcn(A, X)\n",
    "    \n",
    "    test_pred = test_out.max(1)[1].type_as(L)\n",
    "    t_acc = (test_pred.eq(L).double().sum())/L.shape[0]\n",
    "    test_accs.append(t_acc.item())\n",
    "    test_precisions.append(precision_score(L, test_pred))\n",
    "    test_recalls.append(recall_score(L, test_pred))\n",
    "    test_f1s.append(f1_score(L, test_pred))\n",
    "\n",
    "acc = np.array(test_accs).mean()\n",
    "prec = np.array(test_precisions).mean()\n",
    "rec = np.array(test_recalls).mean()\n",
    "f1 = np.array(test_f1s).mean()\n",
    "\n",
    "print(\"GCN - averaged accuracy: {}, precision: {}, recall: {}, f1: {}\".format(acc, prec, rec, f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.088737,
     "end_time": "2022-07-20T23:45:26.490647",
     "exception": false,
     "start_time": "2022-07-20T23:45:26.401910",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "papermill": {
   "duration": 762.581986,
   "end_time": "2022-07-20T23:45:26.686599",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-07-20T23:32:44.104613",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
